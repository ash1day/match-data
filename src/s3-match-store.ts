import { execSync } from 'node:child_process'
import * as fs from 'node:fs'
import { createReadStream } from 'node:fs'
import * as path from 'node:path'
import { PutObjectCommand, S3Client } from '@aws-sdk/client-s3'
import { Database } from 'duckdb-async'
import type { MatchTFTDTO } from 'twisted/dist/models-dto'
import * as zlib from 'zlib'

const BUCKET_NAME = 'tftips'
const PREFIX = 'match-data/'
const S3_REGION = 'ap-northeast-1'

// S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰
let s3Client: S3Client | null = null
function getS3Client(): S3Client {
  if (!s3Client) {
    s3Client = new S3Client({
      region: S3_REGION,
      credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!
      }
    })
  }
  return s3Client
}

/**
 * S3ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢
 *
 * ãƒ•ãƒ­ãƒ¼:
 * 1. S3ã‹ã‚‰æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
 * 2. æ—¢å­˜ã®ãƒãƒƒãƒIDã‚’èª­ã¿è¾¼ã¿
 * 3. æ–°è¦ãƒãƒƒãƒã®ã¿APIå–å¾—
 * 4. æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
 */

const DATA_DIR = process.cwd()

// æ–°è¦ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½è·¡ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ï¼‰
const newlyCreatedFiles: Set<string> = new Set()

/**
 * æ–°è¦ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
 */
export function getNewlyCreatedFiles(): string[] {
  return Array.from(newlyCreatedFiles)
}

/**
 * æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
 */
export function clearNewlyCreatedFiles(): void {
  newlyCreatedFiles.clear()
}

/**
 * S3ã‹ã‚‰æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
 */
export async function downloadFromS3(downloadIndexes = false): Promise<void> {
  console.log('ğŸ“¥ Downloading existing data from S3...')
  try {
    const indexFlag = downloadIndexes ? ' --indexes' : ''
    execSync(`tsx src/sync-s3.ts download${indexFlag}`, { stdio: 'inherit', cwd: DATA_DIR })
    console.log('âœ… Download complete')
  } catch (error) {
    console.warn('âš ï¸ Failed to download from S3 (may be first run):', error)
  }
}

/**
 * S3ã«å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
 */
async function uploadFileToS3(localPath: string, key: string): Promise<void> {
  const fileStream = createReadStream(localPath)
  const command = new PutObjectCommand({
    Bucket: BUCKET_NAME,
    Key: PREFIX + key,
    Body: fileStream
  })

  await getS3Client().send(command)
}

/**
 * S3ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
 */
export async function uploadToS3(_patch?: string): Promise<void> {
  const filesToUpload = getNewlyCreatedFiles()

  if (filesToUpload.length === 0) {
    console.log('ğŸ“¤ No new files to upload')
    return
  }

  console.log(`ğŸ“¤ Uploading ${filesToUpload.length} new files to S3...`)

  for (const file of filesToUpload) {
    const localPath = path.join(DATA_DIR, file)
    if (fs.existsSync(localPath)) {
      console.log(`  Uploading ${file}...`)
      await uploadFileToS3(localPath, file)
    } else {
      console.warn(`  âš ï¸ File not found: ${file}`)
    }
  }

  console.log('âœ… Upload complete')
  clearNewlyCreatedFiles()
}

/**
 * æ—¢å­˜ã®ãƒãƒƒãƒIDã‚’å–å¾—
 */
export async function getExistingMatchIds(region: string, patch: string): Promise<Set<string>> {
  const indexPath = path.join(DATA_DIR, region, patch, 'index.json.gz')

  if (!fs.existsSync(indexPath)) {
    console.log(`  No existing index for ${region}/${patch}`)
    return new Set()
  }

  const compressed = fs.readFileSync(indexPath)
  const decompressed = zlib.gunzipSync(compressed)
  const matchIds = JSON.parse(decompressed.toString()) as string[]

  console.log(`  Found ${matchIds.length} existing matches in ${region}/${patch}`)
  return new Set(matchIds)
}

/**
 * æ–°è¦ãƒãƒƒãƒIDã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
 */
export async function filterNewMatchIds(matchIds: string[], region: string, patch: string): Promise<string[]> {
  const existingIds = await getExistingMatchIds(region, patch)
  const newIds = matchIds.filter((id) => !existingIds.has(id))

  console.log(`  ${newIds.length} new matches to fetch (${existingIds.size} already exist)`)
  return newIds
}

/**
 * ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ–‡å­—åˆ—ã‚’å–å¾— (YYYYMMDD-HHmmss)
 */
function getTimestampString(): string {
  const now = new Date()
  const date = now.toISOString().split('T')[0].replace(/-/g, '')
  const time = now.toTimeString().split(' ')[0].replace(/:/g, '')
  return `${date}-${time}`
}

/**
 * ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆParquetå½¢å¼ã€æ—¥ä»˜åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
 */
export async function saveMatchData(matches: MatchTFTDTO[], region: string, patch: string): Promise<void> {
  const dir = path.join(DATA_DIR, region, patch)
  fs.mkdirSync(dir, { recursive: true })

  const timestamp = getTimestampString()
  const parquetPath = path.join(dir, `${timestamp}.parquet`)

  console.log(`  Saving ${matches.length} matches to ${parquetPath}`)

  // DuckDBã§Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
  const db = await Database.create(':memory:')
  await db.run('INSTALL parquet; LOAD parquet;')

  // JSONã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«èª­ã¿è¾¼ã¿
  const jsonPath = path.join(dir, 'temp_matches.json')
  fs.writeFileSync(
    jsonPath,
    JSON.stringify(matches, (_key, value) => (typeof value === 'bigint' ? value.toString() : value))
  )

  await db.run(`
    CREATE TABLE matches AS
    SELECT
      metadata,
      info
    FROM read_json('${jsonPath}',
      columns = {
        metadata: 'JSON',
        info: 'JSON'
      }
    )
  `)

  // Parquetã¨ã—ã¦ä¿å­˜
  await db.run(`COPY matches TO '${parquetPath}' (FORMAT PARQUET, COMPRESSION ZSTD)`)

  await db.close()

  // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
  fs.unlinkSync(jsonPath)

  // æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è¿½è·¡ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ï¼‰
  const relativePath = path.relative(DATA_DIR, parquetPath)
  newlyCreatedFiles.add(relativePath)

  console.log(`  âœ… Saved ${matches.length} matches to ${parquetPath}`)
}

/**
 * ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
 */
export async function saveMatchIndex(matchIds: string[], region: string, patch: string): Promise<void> {
  const dir = path.join(DATA_DIR, region, patch)
  fs.mkdirSync(dir, { recursive: true })

  const indexPath = path.join(dir, 'index.json.gz')

  // æ—¢å­˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
  let existingIds: string[] = []
  if (fs.existsSync(indexPath)) {
    const compressed = fs.readFileSync(indexPath)
    const decompressed = zlib.gunzipSync(compressed)
    existingIds = JSON.parse(decompressed.toString()) as string[]
  }

  // ãƒãƒ¼ã‚¸ã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–
  const allIds = Array.from(new Set([...existingIds, ...matchIds]))

  // åœ§ç¸®ã—ã¦ä¿å­˜
  const compressed = zlib.gzipSync(
    JSON.stringify(allIds, (_key, value) => (typeof value === 'bigint' ? value.toString() : value))
  )
  fs.writeFileSync(indexPath, compressed)

  // æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è¿½è·¡ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ï¼‰
  const relativePath = path.relative(DATA_DIR, indexPath)
  newlyCreatedFiles.add(relativePath)

  console.log(`  âœ… Saved ${allIds.length} match IDs to index`)
}

/**
 * ãƒ‡ãƒ¼ã‚¿åé›†ãƒ—ãƒ­ã‚»ã‚¹ã®åˆæœŸåŒ–
 */
export async function initDataStore(): Promise<void> {
  // S3ã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆplayers + ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
  await downloadFromS3(true)
}

/**
 * ãƒ‡ãƒ¼ã‚¿åé›†ãƒ—ãƒ­ã‚»ã‚¹ã®å®Œäº†
 */
export async function finalizeDataStore(patch?: string): Promise<void> {
  // S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  await uploadToS3(patch)
}

/**
 * ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
 */
export async function loadPlayerData(region: string): Promise<any> {
  const filePath = path.join(DATA_DIR, region, 'players.json.gz')

  if (!fs.existsSync(filePath)) {
    return null
  }

  const compressed = fs.readFileSync(filePath)
  const decompressed = zlib.gunzipSync(compressed)
  return JSON.parse(decompressed.toString())
}

/**
 * ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
 */
export async function savePlayerData(players: any[], region: string): Promise<void> {
  const dir = path.join(DATA_DIR, region)
  fs.mkdirSync(dir, { recursive: true })

  const filePath = path.join(dir, 'players.json.gz')
  const compressed = zlib.gzipSync(
    JSON.stringify(players, (_key, value) => (typeof value === 'bigint' ? value.toString() : value))
  )
  fs.writeFileSync(filePath, compressed)

  // æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è¿½è·¡ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ï¼‰
  const relativePath = path.relative(DATA_DIR, filePath)
  newlyCreatedFiles.add(relativePath)

  console.log(`  âœ… Saved ${players.length} players to ${filePath}`)
}
